{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature_engine==1.5.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from feature_engine==1.5.2) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from feature_engine==1.5.2) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from feature_engine==1.5.2) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from feature_engine==1.5.2) (1.9.3)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from feature_engine==1.5.2) (0.13.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.0.3->feature_engine==1.5.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.0.3->feature_engine==1.5.2) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->feature_engine==1.5.2) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->feature_engine==1.5.2) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels>=0.11.1->feature_engine==1.5.2) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels>=0.11.1->feature_engine==1.5.2) (23.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine==1.5.2) (1.12.0)\n",
      "Requirement already satisfied: xgboost==1.7.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost==1.7.5) (1.23.5)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost==1.7.5) (1.9.3)\n",
      "Requirement already satisfied: tabpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (2.2.1)\n",
      "Requirement already satisfied: configparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (6.0.0)\n",
      "Requirement already satisfied: coverage in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (6.5.0)\n",
      "Requirement already satisfied: coveralls in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (3.3.1)\n",
      "Requirement already satisfied: docopt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (0.6.2)\n",
      "Requirement already satisfied: future in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (0.18.3)\n",
      "Requirement already satisfied: genson in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (1.2.2)\n",
      "Requirement already satisfied: hypothesis in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (6.87.0)\n",
      "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (4.17.3)\n",
      "Requirement already satisfied: mock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (5.1.0)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (1.23.5)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (1.5.3)\n",
      "Requirement already satisfied: pyopenssl in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (23.2.0)\n",
      "Requirement already satisfied: pytest in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (7.4.2)\n",
      "Requirement already satisfied: pytest-cov in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (4.1.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (2.21.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (1.9.3)\n",
      "Requirement already satisfied: simplejson in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (3.19.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (1.2.2)\n",
      "Requirement already satisfied: textblob in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (0.17.1)\n",
      "Requirement already satisfied: tornado in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (4.5.3)\n",
      "Requirement already satisfied: twisted in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (23.8.0)\n",
      "Requirement already satisfied: urllib3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (1.24.3)\n",
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy) (13.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tabpy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tabpy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tabpy) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hypothesis->tabpy) (22.2.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hypothesis->tabpy) (2.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->tabpy) (0.19.3)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk->tabpy) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk->tabpy) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk->tabpy) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk->tabpy) (4.64.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->tabpy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->tabpy) (2022.7.1)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyopenssl->tabpy) (41.0.4)\n",
      "Requirement already satisfied: iniconfig in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytest->tabpy) (2.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytest->tabpy) (23.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytest->tabpy) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->tabpy) (3.1.0)\n",
      "Requirement already satisfied: automat>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from twisted->tabpy) (22.10.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from twisted->tabpy) (15.1.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from twisted->tabpy) (21.0.0)\n",
      "Requirement already satisfied: incremental>=22.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from twisted->tabpy) (22.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from twisted->tabpy) (4.5.0)\n",
      "Requirement already satisfied: zope-interface>=5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from twisted->tabpy) (6.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from automat>=0.8.0->twisted->tabpy) (1.12.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl->tabpy) (1.15.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from zope-interface>=5->twisted->tabpy) (64.0.2)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl->tabpy) (2.21)\n",
      "Requirement already satisfied: tabpy-client in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy-client) (2.2.1)\n",
      "Requirement already satisfied: decorator in /Users/aprilm/Library/Python/3.11/lib/python/site-packages (from tabpy-client) (5.1.1)\n",
      "Requirement already satisfied: genson in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy-client) (1.2.2)\n",
      "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy-client) (4.17.3)\n",
      "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy-client) (2.8.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tabpy-client) (2.21.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->tabpy-client) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->tabpy-client) (0.19.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil->tabpy-client) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tabpy-client) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tabpy-client) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tabpy-client) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tabpy-client) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install feature_engine==1.5.2\n",
    "! pip install xgboost==1.7.5\n",
    "! pip install tabpy\n",
    "! pip install tabpy-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for saving the pipeline\n",
    "import joblib\n",
    "\n",
    "# from Scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "# from feature-engine\n",
    "from feature_engine.imputation import (\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer,\n",
    ")\n",
    "\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from feature_engine.encoding import OneHotEncoder, OrdinalEncoder\n",
    "from feature_engine.transformation import LogTransformer\n",
    "\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "# set up the pipeline\n",
    "# from feature_engine.transformation import YeoJohnsonTransformer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from feature_engine.selection import DropConstantFeatures, DropDuplicateFeatures, SmartCorrelatedSelection\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    make_scorer, f1_score\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    KFold,\n",
    ")\n",
    "### model evaluation\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode_main</th>\n",
       "      <th>distance</th>\n",
       "      <th>density</th>\n",
       "      <th>age</th>\n",
       "      <th>male</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education</th>\n",
       "      <th>income</th>\n",
       "      <th>cars</th>\n",
       "      <th>license</th>\n",
       "      <th>bicycles</th>\n",
       "      <th>weekend</th>\n",
       "      <th>diversity</th>\n",
       "      <th>green</th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.26259</td>\n",
       "      <td>84</td>\n",
       "      <td>no</td>\n",
       "      <td>native</td>\n",
       "      <td>lower</td>\n",
       "      <td>less20</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.24604</td>\n",
       "      <td>26.881233</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walk</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.26259</td>\n",
       "      <td>84</td>\n",
       "      <td>no</td>\n",
       "      <td>native</td>\n",
       "      <td>lower</td>\n",
       "      <td>less20</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.24604</td>\n",
       "      <td>26.881233</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.76264</td>\n",
       "      <td>27</td>\n",
       "      <td>yes</td>\n",
       "      <td>western</td>\n",
       "      <td>middle</td>\n",
       "      <td>20to40</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.53959</td>\n",
       "      <td>36.045955</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.76264</td>\n",
       "      <td>27</td>\n",
       "      <td>yes</td>\n",
       "      <td>western</td>\n",
       "      <td>middle</td>\n",
       "      <td>20to40</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.53959</td>\n",
       "      <td>36.045955</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>car</td>\n",
       "      <td>61.5</td>\n",
       "      <td>1.76264</td>\n",
       "      <td>27</td>\n",
       "      <td>yes</td>\n",
       "      <td>western</td>\n",
       "      <td>middle</td>\n",
       "      <td>20to40</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.53959</td>\n",
       "      <td>36.045955</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mode_main  distance  density  age male ethnicity education  income  cars  \\\n",
       "0      walk       1.0  1.26259   84   no    native     lower  less20     0   \n",
       "1      walk      10.0  1.26259   84   no    native     lower  less20     0   \n",
       "2       car       3.0  1.76264   27  yes   western    middle  20to40     1   \n",
       "3       car       3.0  1.76264   27  yes   western    middle  20to40     1   \n",
       "4       car      61.5  1.76264   27  yes   western    middle  20to40     1   \n",
       "\n",
       "  license  bicycles weekend  diversity      green  temp  precip  wind  \n",
       "0     yes         1     yes    1.24604  26.881233   0.1    0.10   3.0  \n",
       "1     yes         1     yes    1.24604  26.881233   0.1    0.10   3.0  \n",
       "2     yes         2     yes    1.53959  36.045955  -3.4    0.05   1.8  \n",
       "3     yes         2     yes    1.53959  36.045955  -3.4    0.05   1.8  \n",
       "4     yes         2     yes    1.53959  36.045955  -3.4    0.05   1.8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "data = pd.read_csv('/Users/aprilm/data_science/data_tfm/nts_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Separación del dataset training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((161425, 16), (69183, 16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('mode_main', axis=1),  # predictive variables\n",
    "    data['mode_main'],  # target\n",
    "    test_size=0.3,\n",
    "    random_state=0,  # setting the seed to 0\n",
    "   \n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's enconde the target.\n",
    "target_cat = {'car': 0, 'bike': 1, 'walk':2, 'pt':3 }\n",
    "\n",
    "y_train = y_train.map(target_cat)\n",
    "y_test = y_test.map(target_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pipeline - feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Numerical variables with  Yeo-Johson transformation\n",
    "NUMERICALS_YEO_VARS = ['density', 'diversity', 'green', 'temp', 'wind']\n",
    "\n",
    "# Numerical variables with log transformation\n",
    "NUMERICALS_LOG_VARS = [\"age\", \"distance\"]\n",
    "\n",
    "# categorical variables for encode\n",
    "TWO_CAT = {'yes':1, 'no':0}\n",
    "TWO_VAR = ['male', 'license', 'weekend']\n",
    "\n",
    "\n",
    "# categorical for one hot encoding\n",
    "ONE_HOT_ENCODE_VARS = ['education']\n",
    "\n",
    "#variable mapping\n",
    "INCOME_MAPPING = {'less20': 0, '20to40': 1, 'more40':2}\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Custom transformer class\n",
    "class YeoJohnsonTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, variables=None):\n",
    "        if not isinstance(variables, list):\n",
    "            self.variables = [variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Initialize a PowerTransformer for each variable\n",
    "        self.transformers_ = {}\n",
    "        \n",
    "        for var in self.variables:\n",
    "            transformer = PowerTransformer(method=\"yeo-johnson\", standardize=False)\n",
    "            transformer.fit(X[[var]])\n",
    "            self.transformers_[var] = transformer\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.copy()\n",
    "        \n",
    "        for var in self.variables:\n",
    "            var_tr = var + '_tr'\n",
    "            X[var_tr] = self.transformers_[var].transform(X[[var]])\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "    \n",
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for var in self.variables:\n",
    "            X[var + '_tr'] = np.log(X[var])\n",
    "        return X\n",
    "\n",
    "### ====== CATEGORICAL TRANSFORMATIONS ======\n",
    "# For Ethnicity\n",
    "class EthnicityBinarizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, variable):\n",
    "        self.variable = variable\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Grouping less frequent categories\n",
    "        X[self.variable + '_bin'] = X[self.variable].replace(['western', 'nonwestern'], 'western_nonwestern')\n",
    "        \n",
    "        # Mapping to binary values\n",
    "        ethnicity_cat = {'native': 0, 'western_nonwestern': 1}\n",
    "        X[self.variable + '_bin'] = X[self.variable + '_bin'].map(ethnicity_cat)\n",
    "        \n",
    "        # Dropping the original 'ethnicity' column\n",
    "        X = X.drop(self.variable, axis=1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "# Transformer for 'license', 'weekend', and 'male' and 'income'\n",
    "class Mapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables, mappings, drop_original=True):\n",
    "        self.variables = variables\n",
    "        self.mappings = mappings\n",
    "        self.drop_original = drop_original\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for feature in self.variables:\n",
    "            new_col = feature + \"_bin\" if feature in [\"male\", \"license\", \"weekend\"] else feature + \"_ord\"\n",
    "            X[new_col] = X[feature].map(self.mappings)\n",
    "            if self.drop_original:\n",
    "                X = X.drop(feature, axis=1)\n",
    "        return X\n",
    "    \n",
    "#========= BINARIZE PRECIPITATION ==========\n",
    "\n",
    "# Modifying the BinarizeVariable transformer to retain the original 'precip' column\n",
    "class BinarizeVariable(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, variable, value_map=None, threshold=None):\n",
    "        self.variable = variable\n",
    "        self.value_map = value_map\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if self.value_map:\n",
    "            X[self.variable + '_bin'] = X[self.variable].map(self.value_map)\n",
    "        elif self.threshold is not None:\n",
    "            X[self.variable + '_bin'] = np.where(X[self.variable] > self.threshold, 1, 0)\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pipe = Pipeline([\n",
    "    \n",
    "    # ==== VARIABLE TRANSFORMATION =====\n",
    "    # Apply the column-specific transformations\n",
    "    \n",
    "    ('yeo_johnson', YeoJohnsonTransformer(variables=NUMERICALS_YEO_VARS)),\n",
    "    ('tranformation_log', LogTransformer(variables=NUMERICALS_LOG_VARS)),\n",
    "    \n",
    "     # == CATEGORICAL ENCODING\n",
    "    ('binarize_precip', BinarizeVariable(variable='precip', threshold=0)),\n",
    "    \n",
    "     # === mappers ===\n",
    "    # Binarize specified variables\n",
    "    ('cat_variable', Mapper(variables=TWO_VAR, mappings=TWO_CAT)),\n",
    "\n",
    "     # Handle 'income' variable\n",
    "\n",
    "    ('ordinal_encoder', Mapper(variables=['income'], mappings=INCOME_MAPPING)),\n",
    "\n",
    "    # Handle 'ethnicity' variable\n",
    "    ('ethnicity_binarizer', EthnicityBinarizer(variable='ethnicity')),\n",
    "    \n",
    "    # == CATEGORICAL ENCODING\n",
    "    #one hot encoding\n",
    "    ('one_hot_encode', OneHotEncoder(\n",
    "        variables=ONE_HOT_ENCODE_VARS, drop_last=True)),\n",
    "   \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = fe_pipe.fit_transform(X_train)\n",
    "X_test_transformed = fe_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161425, 25) (69183, 25) (161425,) (69183,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape, X_test_transformed.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['distance', 'density', 'age', 'cars', 'bicycles', 'diversity', 'green',\n",
       "       'temp', 'precip', 'wind', 'density_tr', 'diversity_tr', 'green_tr',\n",
       "       'temp_tr', 'wind_tr', 'age_tr', 'distance_tr', 'precip_bin', 'male_bin',\n",
       "       'license_bin', 'weekend_bin', 'income_ord', 'ethnicity_bin',\n",
       "       'education_higher', 'education_lower'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Equilibro de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SMOTEENN\n",
    "smenn = SMOTEENN(sampling_strategy='auto',random_state=0,\n",
    "        smote=SMOTE(sampling_strategy='auto', random_state=0, k_neighbors=5),\n",
    "        enn=EditedNearestNeighbours(sampling_strategy='auto', n_neighbors=3, kind_sel='all'),n_jobs=4)\n",
    "\n",
    "# Apply transformations\n",
    "X_train_balanced, y_train_balanced = smenn.fit_resample(X_train_transformed, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['distance', 'density', 'age', 'cars', 'bicycles', 'diversity', 'green',\n",
       "       'temp', 'precip', 'wind', 'density_tr', 'diversity_tr', 'green_tr',\n",
       "       'temp_tr', 'wind_tr', 'age_tr', 'distance_tr', 'precip_bin', 'male_bin',\n",
       "       'license_bin', 'weekend_bin', 'income_ord', 'ethnicity_bin',\n",
       "       'education_higher', 'education_lower'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_balanced.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your random forest estimator\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=0,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "# Stack all the selection methods inside a pipeline\n",
    "pipe_model_performance = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=0.998)),\n",
    "    ('duplicated', DropDuplicateFeatures()),\n",
    "    ('correlation_model_performance', SmartCorrelatedSelection(\n",
    "        method='spearman',\n",
    "        missing_values='raise',\n",
    "        scoring='f1_macro',\n",
    "        selection_method='model_performance',\n",
    "        estimator=rf,\n",
    "        cv=3,\n",
    "    )),\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe_model_performance.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Transform the test data using the already fitted pipeline\n",
    "X_train_selected = pipe_model_performance.transform(X_train_balanced)\n",
    "X_test_selected = pipe_model_performance.transform(X_test_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['density', 'cars', 'bicycles', 'diversity', 'green', 'precip',\n",
       "       'temp_tr', 'wind_tr', 'age_tr', 'distance_tr', 'precip_bin', 'male_bin',\n",
       "       'license_bin', 'weekend_bin', 'income_ord', 'ethnicity_bin',\n",
       "       'education_higher', 'education_lower'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_selected.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model with the given hyperparameters\n",
    "# xgb_model = xgb.XGBClassifier(\n",
    "#     objective='multi:softprob',\n",
    "#     colsample_bytree=0.9,\n",
    "#     learning_rate=0.3,\n",
    "#     max_depth=10,\n",
    "#     n_estimators=1000,  # Setting to a large number, early stopping will decide the actual number\n",
    "#     eval_metric='mlogloss',\n",
    "#     subsample=1.0,\n",
    "#     reg_lambda=1.5,\n",
    "#     reg_alpha=0.005,\n",
    "#     random_state=0\n",
    "# )\n",
    "\n",
    "# # Stratified K-Fold Cross-Validation\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# # Scores list to store the F1 macro scores for each fold\n",
    "# scores = []\n",
    "\n",
    "# # Loop over the folds\n",
    "# for train_idx, val_idx in skf.split(X_train_selected, y_train_balanced):\n",
    "#     X_train_fold, X_val_fold = X_train_selected.iloc[train_idx], X_train_selected.iloc[val_idx]\n",
    "#     y_train_fold, y_val_fold = y_train_balanced.iloc[train_idx], y_train_balanced.iloc[val_idx]\n",
    "\n",
    "#     # Fit the model with early stopping\n",
    "#     xgb_model.fit(\n",
    "#         X_train_fold,\n",
    "#         y_train_fold,\n",
    "#         early_stopping_rounds=10,\n",
    "#         eval_set=[(X_val_fold, y_val_fold)],\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "#     # Predict on the validation set\n",
    "#     predictions = xgb_model.predict(X_val_fold)\n",
    "#     score = f1_score(y_val_fold, predictions, average='macro')\n",
    "#     scores.append(score)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Validation F1 (macro) across folds: {[score * 100 for score in scores]}\")\n",
    "# print(f\"Average Validation F1 (macro): {np.mean(scores) * 100:.2f}%\")\n",
    "\n",
    "# # Predict on the entire training data to get the training F1 score\n",
    "# y_train_pred = xgb_model.predict(X_train_selected)\n",
    "# train_f1 = f1_score(y_train_balanced, y_train_pred, average='macro')\n",
    "# print(f\"Training F1 (macro): {train_f1 * 100:.2f}%\")\n",
    "\n",
    "# # Predict on the test data and get the test F1 score\n",
    "# y_test_pred = xgb_model.predict(X_test_selected)\n",
    "# test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "# print(f\"Test F1 (macro): {test_f1 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Precision: 93.65%\n",
      "Recall: 93.54%\n",
      "F1 Score: 93.59%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "Precision: 93.73%\n",
      "Recall: 93.60%\n",
      "F1 Score: 93.66%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "Precision: 93.66%\n",
      "Recall: 93.54%\n",
      "F1 Score: 93.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "Precision: 93.50%\n",
      "Recall: 93.41%\n",
      "F1 Score: 93.45%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n",
      "Precision: 93.65%\n",
      "Recall: 93.55%\n",
      "F1 Score: 93.60%\n",
      "\n",
      "Training Precision: 98.70%\n",
      "Training Recall: 98.67%\n",
      "Training F1: 98.68%\n",
      "Test Precision: 74.36%\n",
      "Test Recall: 67.76%\n",
      "Test F1: 70.32%\n",
      "Average Validation Precision (macro): 93.64%\n",
      "Average Validation Recall (macro): 93.53%\n",
      "Average Validation F1 (macro): 93.58%\n"
     ]
    }
   ],
   "source": [
    "# Define the model with the given hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    colsample_bytree=0.9,\n",
    "    learning_rate=0.3,\n",
    "    max_depth=10,\n",
    "    n_estimators=1000,  # Setting to a large number, early stopping will decide the actual number\n",
    "    eval_metric='mlogloss',\n",
    "    subsample=1.0,\n",
    "    reg_lambda=1.5,\n",
    "    reg_alpha=0.005,\n",
    "    random_state=0\n",
    ")\n",
    "    \n",
    "#Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "    \n",
    "# Initialize lists to store precision and recall scores for each fold\n",
    "precisions = []\n",
    "recalls = []\n",
    "scores = [] \n",
    "\n",
    "# Loop over the folds\n",
    "for fold_num, (train_idx, val_idx) in enumerate(skf.split(X_train_selected, y_train_balanced), start=1):\n",
    "    X_train_fold, X_val_fold = X_train_selected.iloc[train_idx], X_train_selected.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_balanced.iloc[train_idx], y_train_balanced.iloc[val_idx]\n",
    "    \n",
    "    # Fit the model with early stopping\n",
    "    xgb_model.fit(\n",
    "        X_train_fold,\n",
    "        y_train_fold,\n",
    "        early_stopping_rounds=10,\n",
    "        eval_set=[(X_val_fold, y_val_fold)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    predictions = xgb_model.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate Precision, Recall, and F1 Score for the validation set\n",
    "    precision = precision_score(y_val_fold, predictions, average='macro')\n",
    "    recall = recall_score(y_val_fold, predictions, average='macro')\n",
    "    score = f1_score(y_val_fold, predictions, average='macro')\n",
    "    \n",
    "    # Append the scores to the respective lists\n",
    "    scores.append(score)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    \n",
    "    # Print results for the current fold\n",
    "    print(f\"Fold {fold_num}:\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {score * 100:.2f}%\")\n",
    "    print()\n",
    "\n",
    "# Calculate and print Precision, Recall, and F1 Score for the entire training set\n",
    "y_train_pred = xgb_model.predict(X_train_selected)\n",
    "train_precision = precision_score(y_train_balanced, y_train_pred, average='macro')\n",
    "train_recall = recall_score(y_train_balanced, y_train_pred, average='macro')\n",
    "train_f1 = f1_score(y_train_balanced, y_train_pred, average='macro')\n",
    "\n",
    "print(f\"Training Precision: {train_precision * 100:.2f}%\")\n",
    "print(f\"Training Recall: {train_recall * 100:.2f}%\")\n",
    "print(f\"Training F1: {train_f1 * 100:.2f}%\")\n",
    "\n",
    "# Calculate and print Precision, Recall, and F1 Score for the test set\n",
    "y_test_pred = xgb_model.predict(X_test_selected)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f\"Test Precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test Recall: {test_recall * 100:.2f}%\")\n",
    "print(f\"Test F1: {test_f1 * 100:.2f}%\")\n",
    "\n",
    "# Print average results across folds\n",
    "print(f\"Average Validation Precision (macro): {np.mean(precisions) * 100:.2f}%\")\n",
    "print(f\"Average Validation Recall (macro): {np.mean(recalls) * 100:.2f}%\")\n",
    "print(f\"Average Validation F1 (macro): {np.mean(scores) * 100:.2f}%\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
